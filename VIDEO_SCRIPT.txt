===============================================================================
        CF-MADRL: INTELLIGENT TRAFFIC SIGNAL CONTROL SYSTEM
                    2-MINUTE VIDEO DEMONSTRATION SCRIPT
===============================================================================

[INTRO & CODEBASE OVERVIEW - 25 seconds]
----------------------------------------
Good morning. I'm Dharmananda Joshi, presenting our project on intelligent 
traffic signal control using federated learning and multi-agent reinforcement 
learning.

We're grateful to our supervisor, Er. Sudip Rana Sir, for his guidance.



Today I'll walk you through how we trained our intelligent agents and how we 
have planned to deploy them on edge devices.



Let me start by showing you our codebase structure:

CF-MADRL-YOLO contains the YOLO model training specific codes for vehicle 
detection.

Learn folder is for our learning experiments. 

Logs contains training, evaluation, and normalization statistics. 

Pi contains all files to be deployed into Raspberry Pi. 

Plots contains our training and evaluation visualizations. 

Saved_models stores our trained agent policies. 

Scripts contains scripts for training in colab. 

Src contains our RL training files. 

Sumo_files contain our simulation networks. 

And tools contains utility scripts.




[KEY FILES - 30 seconds]
------------------------
Now let me show you the key implementation files.



[SHOW FILE: config.yaml]
This is our main configuration. 

Here we set simulation parameters, training settings/hyperparameters, and evaluation configurations.






[SHOW FILE: src/agent_manager.py ~ PPOConfig section]
Here we create PPO agents for each junction. 

PPOConfig sets the learning rate, neural network size, and other hyperparameters. 

Each junction gets its own independent agent.





[SHOW FILE: src/federation.py ~ clustering and aggregation section]
This is our innovation - federated learning with clustering. 

We use K-Means to group similar junctions by traffic patterns. 

Then we aggregate weights within each cluster and redistribute them back to agents. 

This way they learn together.




[SHOW FILE: src/multi_agent_sumo_env.py ~ reset, step, reward section]
This is the environment. 

Agents observe junction state - vehicle counts, queue lengths. 

They choose a phase and duration. 

We calculate rewards based on queue and wait time reduction. 

Agents learn through trial and error.






[DEPLOYMENT - 12 seconds]
-------------------------
After training, we deploy everything to Raspberry Pi for real-world use.


In the pi/ folder, we have:

pi/models/model.pt - these are our trained policy weights, ready to use.



pi/utils/model.py - this loads the model and makes predictions. 

Given a traffic state, it outputs the best action that reduces queue and wait time.






pi/main.py - this is the main inference loop that constantly runs on the Pi. 

It reads the junction state through YOLO, 
passes it to our policy, 
gets the decision, 
and sends the signal timing to the hardware 
that controls the actual traffic lights.





[CONCLUSION - 3 seconds]
------------------------
So that's our complete system.


Thank you.





===============================================================================
                            QUICK REFERENCE
===============================================================================

TIMING:
- Intro & Codebase: 25s
- Key Files: 30s  
- Deployment: 12s
- Conclusion: 3s
TOTAL: ~70 seconds

FILES TO OPEN IN ORDER:
1. config.yaml - show any config parameters
2. src/agent_manager.py - scroll to PPOConfig() section
3. src/federation.py - show K-Means clustering and weight aggregation code
4. src/multi_agent_sumo_env.py - show reset(), step(), reward calculation
5. pi/ folder - show file structure

WHAT TO POINT AT:
- config.yaml: training parameters, rl settings
- agent_manager.py: PPOConfig( ) initialization
- federation.py: kmeans clustering, weight averaging logic
- multi_agent_sumo_env.py: observation space, action space, step function, reward
- pi/: models/, utils/, main.py

TIPS:
✓ Speak naturally - pause between files
✓ Point at code as you mention it
✓ Don't read code line-by-line, explain what it does
✓ Let the structure speak for itself

===============================================================================
